{
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "language_info": {
            "name": "python",
            "version": "3.7.0",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat_minor": 2,
    "nbformat": 4,
    "cells": [
        {
            "cell_type": "markdown",
            "source": "# Json or PSCustomObject?\r\n\r\nThis is a first for me. \r\n\r\nI'm working on storing past runs of dbachecks into a database so I can see improvements, changes,  etc.\r\nI've been saving them off for a while now so there's quite a lot of data there as well. \r\n\r\n\r\n\r\n",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": "",
            "metadata": {},
            "outputs": [],
            "execution_count": 0
        },
        {
            "cell_type": "markdown",
            "source": "I can use that for load testing, performance tuning practice, etc.\r\n\r\nDo I decide to input the data into the database in Json format, and have the database do the work on parsing and splitting the data, or do I do the work in PowerShell and input the data already parsed and split?\r\n\r\nThere are already ideas racing through my head on which to use. I'm thinking that pre-parsed is the way to do but SQL Server has the ability to work with Json now. And, if I'm being honest with myself, I've been procrastinating with my SQL Server - Json learnings.\r\n\r\nSo let's see if we can figure out a difference and decide on a winner!\r\n\r\n## Testing the options\r\n\r\nWe're going \r\n\r\n### Json",
            "metadata": {}
        }
    ]
}